{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4lQGaBpSHLU-"
   },
   "source": [
    "# Deep Crossentropy method\n",
    "\n",
    "In this section we'll extend your CEM implementation with neural networks! You will train a multi-layer neural network to solve simple continuous state space games. __Please make sure you're done with tabular crossentropy method from the previous notebook.__\n",
    "\n",
    "![img](https://tip.duke.edu/independent_learning/greek/lesson/digging_deeper_final.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "rmzSc5AbHLVB",
    "outputId": "6d871975-4aa3-43c0-ec7a-c51571001bf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting virtual X frame buffer: Xvfb.\n"
     ]
    }
   ],
   "source": [
    "# import sys, os\n",
    "# if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
    "#     !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/spring20/setup_colab.sh -O- | bash\n",
    "\n",
    "#     !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/grading.py -O ../grading.py\n",
    "#     !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/week1_intro/submit.py\n",
    "\n",
    "#     !touch .setup_complete\n",
    "\n",
    "# # This code creates a virtual display to draw game images on.\n",
    "# # It will have no effect if your machine has a monitor.\n",
    "# if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
    "#     !bash ../xvfb start\n",
    "#     os.environ['DISPLAY'] = ':1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "VbqrvTDcHLVZ",
    "outputId": "597496e9-119d-4f30-d810-870d6590b289"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state vector dim = 4\n",
      "n_actions = 2\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# if you see \"<classname> has no attribute .env\", remove .env or update gym\n",
    "env = gym.make(\"CartPole-v0\").env\n",
    "\n",
    "env.reset()\n",
    "n_actions = env.action_space.n\n",
    "state_dim = env.observation_space.shape[0]\n",
    "\n",
    "#plt.imshow(env.render(\"rgb_array\", ))\n",
    "print(\"state vector dim =\", state_dim)\n",
    "print(\"n_actions =\", n_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3R93dsobHLVk"
   },
   "source": [
    "# Neural Network Policy\n",
    "\n",
    "For this assignment we'll utilize the simplified neural network implementation from __[Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)__. Here's what you'll need:\n",
    "\n",
    "* `agent.partial_fit(states, actions)` - make a single training pass over the data. Maximize the probabilitity of :actions: from :states:\n",
    "* `agent.predict_proba(states)` - predict probabilities of all actions, a matrix of shape __[len(states), n_actions]__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "BMdV-DGAIEua",
    "outputId": "492e482c-7a8f-4a45-e1b3-0702db7b78ce"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "colab_type": "code",
    "id": "Zs1eDMyGHLVn",
    "outputId": "7eb2a51e-35dd-440c-d765-1a562ef7a28b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(20, 20), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "agent = MLPClassifier(\n",
    "    hidden_layer_sizes=(20, 20),\n",
    "    activation='tanh',\n",
    "    warm_start=True\n",
    ")\n",
    "\n",
    "# initialize agent to the dimension of state space and number of actions\n",
    "agent.partial_fit([env.reset()] * n_actions, range(n_actions), range(n_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.29405128, 0.70594872])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.predict_proba([env.reset()])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cPfIbJLoHLVx"
   },
   "outputs": [],
   "source": [
    "def generate_session(env, agent, t_max=1000):\n",
    "    \"\"\"\n",
    "    Play a single game using agent neural network.\n",
    "    Terminate when game finishes or after :t_max: steps\n",
    "    \"\"\"\n",
    "    states, actions = [], []\n",
    "    total_reward = 0\n",
    "\n",
    "    s = env.reset()\n",
    "\n",
    "    for t in range(t_max):\n",
    "        \n",
    "        # use agent to predict a vector of action probabilities for state :s:\n",
    "        probs = agent.predict_proba([env.state])[0]\n",
    "\n",
    "        assert probs.shape == (n_actions,), \"make sure probabilities are a vector (hint: np.reshape)\"\n",
    "        \n",
    "        # use the probabilities you predicted to pick an action\n",
    "        # sample proportionally to the probabilities, don't just take the most likely action\n",
    "        #a = <YOUR CODE>\n",
    "        a = np.random.choice\n",
    "        \n",
    "        a = np.random.choice(np.array([0,1]),p = probs)\n",
    "        # ^-- hint: try np.random.choice\n",
    "\n",
    "        new_s, r, done, info = env.step(a)\n",
    "\n",
    "        # record sessions like you did before\n",
    "        states.append(s)\n",
    "        actions.append(a)\n",
    "        total_reward += r\n",
    "\n",
    "        s = new_s\n",
    "        if done:\n",
    "            break\n",
    "    return states, actions, total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Ca_U2F_HLV4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states: [[ 0.00861038  0.01234419  0.04206843  0.03060581]\n",
      " [ 0.00885726  0.2068384   0.04268055 -0.24851291]\n",
      " [ 0.01299403  0.40132566  0.03771029 -0.52743385]\n",
      " [ 0.02102055  0.5958973   0.02716162 -0.80799961]\n",
      " [ 0.03293849  0.79063669  0.01100162 -1.09201643]]\n",
      "actions: [1, 1, 1, 1, 0]\n",
      "reward: 5.0\n"
     ]
    }
   ],
   "source": [
    "dummy_states, dummy_actions, dummy_reward = generate_session(env, agent, t_max=5)\n",
    "print(\"states:\", np.stack(dummy_states))\n",
    "print(\"actions:\", dummy_actions)\n",
    "print(\"reward:\", dummy_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h66GD_ezHLWA"
   },
   "source": [
    "### CEM steps\n",
    "Deep CEM uses exactly the same strategy as the regular CEM, so you can copy your function code from previous notebook.\n",
    "\n",
    "The only difference is that now each observation is not a number but a `float32` vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A7FNy0CiHLWB"
   },
   "outputs": [],
   "source": [
    "def select_elites(states_batch, actions_batch, rewards_batch, percentile=50):\n",
    "    \"\"\"\n",
    "    Select states and actions from games that have rewards >= percentile\n",
    "    :param states_batch: list of lists of states, states_batch[session_i][t]\n",
    "    :param actions_batch: list of lists of actions, actions_batch[session_i][t]\n",
    "    :param rewards_batch: list of rewards, rewards_batch[session_i]\n",
    "\n",
    "    :returns: elite_states,elite_actions, both 1D lists of states and respective actions from elite sessions\n",
    "\n",
    "    Please return elite states and actions in their original order \n",
    "    [i.e. sorted by session number and timestep within session]\n",
    "\n",
    "    If you are confused, see examples below. Please don't assume that states are integers\n",
    "    (they will become different later).\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    reward_threshold = np.percentile(rewards_batch, percentile)\n",
    "    elite_states=[]\n",
    "    elite_actions=[]\n",
    "\n",
    "\n",
    "    for state, reward in zip(states_batch, rewards_batch):\n",
    "        if reward >= reward_threshold:\n",
    "            elite_states.extend(state)\n",
    "\n",
    "    for action, reward in zip(actions_batch, rewards_batch):\n",
    "        if reward >= reward_threshold:\n",
    "            elite_actions.extend(action)\n",
    "    return elite_states, elite_actions\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZrKWJz8_HLWI"
   },
   "source": [
    "# Training loop\n",
    "Generate sessions, select N best and fit to those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qGy2ZuvUHLWJ"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def show_progress(rewards_batch, log, percentile, reward_range=[-990, +10]):\n",
    "    \"\"\"\n",
    "    A convenience function that displays training progress. \n",
    "    No cool math here, just charts.\n",
    "    \"\"\"\n",
    "\n",
    "    mean_reward = np.mean(rewards_batch)\n",
    "    threshold = np.percentile(rewards_batch, percentile)\n",
    "    log.append([mean_reward, threshold])\n",
    "\n",
    "    clear_output(True)\n",
    "    print(\"mean reward = %.3f, threshold=%.3f\" % (mean_reward, threshold))\n",
    "    plt.figure(figsize=[8, 4])\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(list(zip(*log))[0], label='Mean rewards')\n",
    "    plt.plot(list(zip(*log))[1], label='Reward thresholds')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(rewards_batch, range=reward_range)\n",
    "    plt.vlines([np.percentile(rewards_batch, percentile)],\n",
    "               [0], [100], label=\"percentile\", color='red')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JarjVKquHLWP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean reward = 398.450, threshold=456.000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You Win! You may stop training now via KeyboardInterrupt.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-3aeb390e5ac1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# generate new sessions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mstates_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-3aeb390e5ac1>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# generate new sessions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mstates_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-b07e59e047e5>\u001b[0m in \u001b[0;36mgenerate_session\u001b[0;34m(env, agent, t_max)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# use agent to predict a vector of action probabilities for state :s:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_actions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"make sure probabilities are a vector (hint: np.reshape)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \"\"\"\n\u001b[1;32m   1071\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    665\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mdecision\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \"\"\"\n\u001b[0;32m--> 667\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;31m# Make sure self.hidden_layer_sizes is a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    529\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_sessions = 100\n",
    "percentile = 70\n",
    "log = []\n",
    "\n",
    "for i in range(100):\n",
    "    # generate new sessions\n",
    "    sessions = [generate_session(env, agent, t_max=10000) for _ in range(100)]\n",
    "    \n",
    "    states_batch, actions_batch, rewards_batch = map(np.array, zip(*sessions))\n",
    "\n",
    "    elite_states, elite_actions = select_elites(states_batch, actions_batch, rewards_batch)\n",
    "    #<YOUR CODE: partial_fit agent to predict elite_actions(y) from elite_states(X)>\n",
    "\n",
    "    \n",
    "    agent.partial_fit(elite_states, elite_actions)\n",
    "    #agent.predict_proba()\n",
    "    show_progress(rewards_batch, log, percentile, reward_range=[0, np.max(rewards_batch)])\n",
    "\n",
    "    if np.mean(rewards_batch) > 190:\n",
    "        print(\"You Win! You may stop training now via KeyboardInterrupt.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "frbg52xIHLWW"
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "colab_type": "code",
    "id": "cWaLOzcVHLWY",
    "outputId": "4cf1ed8c-b31e-4c0a-b356-27bd30239962"
   },
   "outputs": [],
   "source": [
    "# Record sessions\n",
    "\n",
    "import gym.wrappers\n",
    "\n",
    "with gym.wrappers.Monitor(gym.make(\"CartPole-v0\"), directory=\"videos\", force=True) as env_monitor:\n",
    "    sessions = [generate_session(env_monitor, agent) for _ in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "colab_type": "code",
    "id": "HMM2RAACHLWf",
    "outputId": "9ce950c4-3e3c-4846-fdc6-0e500209d92d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"videos/openaigym.video.0.13158.video000064.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show video. This may not work in some setups. If it doesn't\n",
    "# work for you, you can download the videos and view them locally.\n",
    "\n",
    "from pathlib import Path\n",
    "from IPython.display import HTML\n",
    "\n",
    "video_names = sorted([s for s in Path('videos').iterdir() if s.suffix == '.mp4'])\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(video_names[-1]))  # You can also try other indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wORoQCPsHLWl"
   },
   "source": [
    "## Assignment: MountainCar\n",
    "\n",
    "By this moment you should have got enough score on [CartPole-v0](https://gym.openai.com/envs/CartPole-v0) to consider it solved (see the link). It's time to try something harder.\n",
    "\n",
    "_if you have any trouble with CartPole-v0 and feel stuck, take a look at the forums_\n",
    "\n",
    "Your assignment is to obtain average reward of __at least -150__ on `MountainCar-v0`.\n",
    "\n",
    "See the tips section below, it's kinda important.\n",
    "  \n",
    "* Bonus quest: Devise a way to speed up training against the default version\n",
    "  * Obvious improvement: use [joblib](https://www.google.com/search?client=ubuntu&channel=fs&q=joblib&ie=utf-8&oe=utf-8)\n",
    "  * Try re-using samples from 3-5 last iterations when computing threshold and training\n",
    "  * Experiment with amount of training iterations and learning rate of the neural network (see params)\n",
    "  \n",
    "  \n",
    "### Tips\n",
    "* Gym page: [MountainCar](https://gym.openai.com/envs/MountainCar-v0)\n",
    "* Sessions for MountainCar may last for 10k+ ticks. Make sure ```t_max``` param is at least 10k.\n",
    " * Also it may be a good idea to cut rewards via \">\" and not \">=\". If 90% of your sessions get reward of -10k and 10% are better, than if you use percentile 20% as threshold, R >= threshold __fails cut off bad sessions__ whule R > threshold works alright.\n",
    "* _issue with gym_: Some versions of gym limit game time by 200 ticks. This will prevent cem training in most cases. Make sure your agent is able to play for the specified __t_max__, and if it isn't, try `env = gym.make(\"MountainCar-v0\").env` or otherwise get rid of TimeLimit wrapper.\n",
    "* If it won't train it's a good idea to plot reward distribution and record sessions: they may give you some clue. If they don't, call course staff :)\n",
    "* 20-neuron network is probably not enough, feel free to experiment.\n",
    "\n",
    "You may find the following snippet useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A5ZNZoL2HLWm"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 4 is different from 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-cd7f2428d2bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MountainCar-v0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0menv_vis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisualize_mountain_car\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_vis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-cd7f2428d2bb>\u001b[0m in \u001b[0;36mvisualize_mountain_car\u001b[0;34m(env, agent)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeshgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mgrid_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \"\"\"\n\u001b[1;32m   1071\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    683\u001b[0m                                          layer_units[i + 1])))\n\u001b[1;32m    684\u001b[0m         \u001b[0;31m# forward propagate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_forward_pass\u001b[0;34m(self, activations)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers_\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             activations[i + 1] = safe_sparse_dot(activations[i],\n\u001b[0;32m--> 104\u001b[0;31m                                                  self.coefs_[i])\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercepts_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 4 is different from 2)"
     ]
    }
   ],
   "source": [
    "def visualize_mountain_car(env, agent):\n",
    "    xs = np.linspace(env.min_position, env.max_position, 100)\n",
    "    vs = np.linspace(-env.max_speed, env.max_speed, 100)\n",
    "    grid = np.dstack(np.meshgrid(xs, vs)).transpose(1, 0, 2)\n",
    "    grid_flat = grid.reshape(len(xs) * len(vs), 2)\n",
    "    probs = agent.predict_proba(grid_flat).reshape(len(xs), len(vs), 3)\n",
    "    return probs\n",
    "\n",
    "with gym.make('MountainCar-v0').env as env_vis:\n",
    "    plt.imshow(visualize_mountain_car(env_vis, agent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PeWottSEHLWt"
   },
   "outputs": [],
   "source": [
    "# Implement generate_session_mountain_car(), training loop, etc.\n",
    "\n",
    "def generate_session_mountain_car(env, agent, t_max=10000):\n",
    "    <YOUR CODE>\n",
    "    \n",
    "    return states, actions, total_reward\n",
    "\n",
    "<YOUR CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9RVXBLFLHLW1"
   },
   "source": [
    "### Submit to Coursera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zCFjYNHbHLW2"
   },
   "outputs": [],
   "source": [
    "from submit import submit_mountain_car\n",
    "submit_mountain_car(generate_session_mountain_car, agent, 'your.email@example.com', 'YourAssignmentToken')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "  \"deep_crossentropy_method.ipynb\"",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
